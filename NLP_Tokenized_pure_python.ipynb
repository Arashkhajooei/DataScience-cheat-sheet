{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmJcWFgzgAAg0OdR8LtIRM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arashkhgit/DataScience-cheat-sheet/blob/main/NLP_Tokenized_pure_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVLRs4ejOECx",
        "outputId": "835413b5-1c7c-4064-a042-5b982cbf88b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choose a language (english/spanish): english\n",
            "Word            Length     Occurrences Histogram                     \n",
            "=======================================================\n",
            "is              2          2          **                            \n",
            "my              2          2          **                            \n",
            "a               1          1          *                             \n",
            "hi              2          1          *                             \n",
            "for             3          1          *                             \n",
            "nlp             3          1          *                             \n",
            "file            4          1          *                             \n",
            "name            4          1          *                             \n",
            "task            4          1          *                             \n",
            "text            4          1          *                             \n",
            "this            4          1          *                             \n",
            "arash           5          1          *                             \n",
            "sample          6          1          *                             \n",
            "\n",
            "Statistical Analysis:\n",
            "Number of Unique Words: 13\n",
            "Average Length of Words: 3.20\n",
            "Maximum Length of Words: 6\n",
            "Minimum Length of Words: 1\n",
            "Mode of Words: is\n",
            "Least Occurring Word: sample\n",
            "\n",
            "========================= Stop Words for English =========================\n",
            "Stop Word       Occurrences\n",
            "=========================\n",
            "a               1         \n",
            "an              0         \n",
            "and             0         \n",
            "the             0         \n",
            "in              0         \n",
            "on              0         \n",
            "at              0         \n",
            "of              0         \n",
            "for             1         \n",
            "to              0         \n",
            "is              2         \n",
            "are             0         \n",
            "was             0         \n",
            "were            0         \n",
            "it              0         \n",
            "that            0         \n",
            "this            1         \n",
            "\n",
            "Choose your search option (word_length/occurrences): word_length\n",
            "Enter the desired word length: 3\n",
            "Matching words:\n",
            "for\n",
            "nlp\n",
            "Analysis completed. Output saved to: output.txt\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Dictionary of stop words for different languages\n",
        "stop_words = {\n",
        "    \"english\": [\n",
        "        \"a\", \"an\", \"and\", \"the\", \"in\", \"on\", \"at\", \"of\", \"for\", \"to\", \"is\", \"are\", \"was\", \"were\", \"it\", \"that\", \"this\"\n",
        "        # Add more English stop words as needed\n",
        "    ],\n",
        "    \"spanish\": [\n",
        "        \"un\", \"una\", \"y\", \"en\", \"el\", \"la\", \"los\", \"de\", \"para\", \"a\", \"es\", \"son\", \"fue\", \"fueron\", \"eso\", \"este\"\n",
        "        # Add more Spanish stop words as needed\n",
        "    ]\n",
        "    # Add stop words for other languages here\n",
        "}\n",
        "\n",
        "def tokenize_text(text):\n",
        "    # Use regular expression to split the text into words (tokens)\n",
        "    # This regex pattern will consider words with letters, digits, and underscores as valid tokens\n",
        "    return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "def analyze_text(text, language=\"english\", output_file=\"output.txt\"):\n",
        "    global word_occurrences\n",
        "    tokens = tokenize_text(text)\n",
        "    word_occurrences = {}\n",
        "    total_word_length = 0\n",
        "\n",
        "    for word in tokens:\n",
        "        # Count occurrences and calculate word length\n",
        "        word_occurrences[word] = word_occurrences.get(word, 0) + 1\n",
        "        total_word_length += len(word)\n",
        "\n",
        "    # Sort the word_occurrences dictionary based on occurrences, word length, and alphabetically\n",
        "    sorted_occurrences = sorted(word_occurrences.items(), key=lambda item: (-item[1], len(item[0]), item[0]))\n",
        "\n",
        "    with open(output_file, \"w\") as file:\n",
        "        # Write the table with histogram to the file\n",
        "        file.write(\"{:<15} {:<10} {:<10} {:<30}\\n\".format(\"Word\", \"Length\", \"Occurrences\", \"Histogram\"))\n",
        "        file.write(\"=\" * 55 + \"\\n\")\n",
        "        for word, occurrences in sorted_occurrences:\n",
        "            word_length = len(word)\n",
        "            histogram = \"*\" * occurrences\n",
        "            file.write(\"{:<15} {:<10} {:<10} {:<30}\\n\".format(word, word_length, occurrences, histogram))\n",
        "\n",
        "        # Perform statistical analysis\n",
        "        num_unique_words = len(word_occurrences)\n",
        "        average_word_length = total_word_length / len(tokens)\n",
        "        max_word_length = max(len(word) for word in tokens)\n",
        "        min_word_length = min(len(word) for word in tokens)\n",
        "        mode_word = sorted_occurrences[0][0]\n",
        "        least_word = sorted_occurrences[-1][0]\n",
        "\n",
        "        # Write the statistics to the file\n",
        "        file.write(\"\\nStatistical Analysis:\\n\")\n",
        "        file.write(\"Number of Unique Words: {}\\n\".format(num_unique_words))\n",
        "        file.write(\"Average Length of Words: {:.2f}\\n\".format(average_word_length))\n",
        "        file.write(\"Maximum Length of Words: {}\\n\".format(max_word_length))\n",
        "        file.write(\"Minimum Length of Words: {}\\n\".format(min_word_length))\n",
        "        file.write(\"Mode of Words: {}\\n\".format(mode_word))\n",
        "        file.write(\"Least Occurring Word: {}\\n\".format(least_word))\n",
        "\n",
        "        # Analyze stop words\n",
        "        language = language.lower()\n",
        "        if language in stop_words:\n",
        "            stop_word_occurrences = {word: word_occurrences.get(word, 0) for word in stop_words[language]}\n",
        "        else:\n",
        "            file.write(f\"\\nStop words not available for the '{language}' language.\\n\")\n",
        "            return\n",
        "\n",
        "        # Write the table for stop words to the file\n",
        "        separator = \"=\" * 25\n",
        "        file.write(f\"\\n{separator} Stop Words for {language.capitalize()} {separator}\\n\")\n",
        "        file.write(\"{:<15} {:<10}\\n\".format(\"Stop Word\", \"Occurrences\"))\n",
        "        file.write(\"=\" * 25 + \"\\n\")\n",
        "        for word, occurrences in stop_word_occurrences.items():\n",
        "            file.write(\"{:<15} {:<10}\\n\".format(word, occurrences))\n",
        "\n",
        "    # Read and print the content of the output file\n",
        "    with open(output_file, \"r\") as file:\n",
        "        output_content = file.read()\n",
        "        print(output_content)\n",
        "\n",
        "def get_user_choice(message, options):\n",
        "    while True:\n",
        "        user_input = input(message).lower()\n",
        "        if user_input in options:\n",
        "            return user_input\n",
        "        else:\n",
        "            print(\"Invalid input. Please choose a valid option.\")\n",
        "\n",
        "def get_user_input(message, variable_type):\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(message)\n",
        "            if variable_type == int:\n",
        "                return int(user_input)\n",
        "            elif variable_type == str:\n",
        "                return user_input\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a valid value.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"/content/file.txt\"\n",
        "    output_file = \"output.txt\"\n",
        "    try:\n",
        "        with open(file_path, \"r\") as file:\n",
        "            file_contents = file.read()\n",
        "            # Get user input for the desired language\n",
        "            language = get_user_choice(\"Choose a language (english/spanish): \", [\"english\", \"spanish\"])\n",
        "\n",
        "            # Call analyze_text with the chosen language\n",
        "            analyze_text(file_contents, language=language, output_file=output_file)\n",
        "\n",
        "            # Get user input for the user's choice (word length or occurrences)\n",
        "            choice = get_user_choice(\"Choose your search option (word_length/occurrences): \", [\"word_length\", \"occurrences\"])\n",
        "\n",
        "            if choice == \"word_length\":\n",
        "                target_word_length = get_user_input(\"Enter the desired word length: \", int)\n",
        "                # Find words matching the given word length in word_occurrences\n",
        "                matching_words = [word for word, occurrences in word_occurrences.items() if len(word) == target_word_length]\n",
        "            else:\n",
        "                target_occurrences = get_user_input(\"Enter the desired number of occurrences: \", int)\n",
        "                # Find words matching the given number of occurrences in word_occurrences\n",
        "                matching_words = [word for word, occurrences in word_occurrences.items() if occurrences == target_occurrences]\n",
        "\n",
        "            # Display the matching words\n",
        "            if matching_words:\n",
        "                print(\"Matching words:\")\n",
        "                for word in matching_words:\n",
        "                    print(word)\n",
        "            else:\n",
        "                print(\"No words match the given criteria.\")\n",
        "\n",
        "        print(\"Analysis completed. Output saved to:\", output_file)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File not found: {file_path}\")\n",
        "    except IOError:\n",
        "        print(f\"Error reading the file: {file_path}\")\n"
      ]
    }
  ]
}